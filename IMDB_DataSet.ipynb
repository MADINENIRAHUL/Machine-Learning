{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e91430a-54df-41ef-923c-716bcaefe402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91036265-9f9c-445c-9684-68179e196257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/rahul/OneDrive/Desktop/Internship/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9208afcd-4aa5-4d5a-af06-203bc0b9f3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94f21f-2038-49e4-8c8b-e3c22af58854",
   "metadata": {},
   "source": [
    "## LOWER CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ac8714-ca22-41a8-8dde-1a207e846471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13b2ec5-2a28-419c-999c-b22ca1e723b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e1aa9-ade8-4eca-84d5-6443fd8988e8",
   "metadata": {},
   "source": [
    "## REMOVING HTML TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915510f7-9ffb-40e3-a900-2b49fdce5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions \n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d27a13-5635-4962-a9f7-b300878415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e63fcc-a750-4146-8a29-758834cc0fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e09452-1136-459b-a377-33989bf54aad",
   "metadata": {},
   "source": [
    "## REMOVE URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a01259b-849a-43b9-95d9-df24e11c5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'https?://\\s+\\www.\\.\\s+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f14ab7-7467-480a-89cb-c65c72d8e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]=df['review'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede9c7da-a738-4907-b267-cac964af7ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a32bc-9b76-4685-9df5-fdf1ba97226f",
   "metadata": {},
   "source": [
    "## REMOVE PUNCTUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a21be95-970c-4eb3-99ee-e45a3a62a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6a4d90-24f4-4d52-a765-f68b160d35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3217a27e-f535-4723-bc45-fdb1027ca959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",exclude))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57e68555-e24a-47f3-91ec-11af6e0d6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "619d4471-b6fc-409e-bdae-12f9afb2037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going to have to disagree with the previous...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production the filming tech...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically theres a family where a little boy j...  negative\n",
       "4      petter matteis love in the time of money is a ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  im going to have to disagree with the previous...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44e308-532a-404a-b97c-c6a757298d23",
   "metadata": {},
   "source": [
    "## REMOVING STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "816d8aad-7028-4393-bd20-289462723e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac7bce87-4874-4547-b6f2-3f9efb72d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14624035-a934-4dcd-855d-175680a17b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81424dc0-d7d3-49bd-b0ec-d319e22b9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x= new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83467ff4-ad8b-4d12-801b-227a0e69b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "473ab76b-6194-44c4-93b4-6d4b73a22f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2db7a-4502-4ff7-9d5b-6ab0643275e9",
   "metadata": {},
   "source": [
    "## HANDLING EMOJI'S\n",
    "### If we have emojis in the text, we have to options:\n",
    "#### Removing Emoji's (OR)\n",
    "#### Replacing emojis in the form of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b971e80f-8e8d-48da-8475-a4136517aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile('['\"u\\U0001F600-\\U0001F64F\"  # Emotions\n",
    "                               \"u\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                               \"u\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                               \"u\\U0001F1E0-\\U0001F1FF\"  # Flags(iOS)\n",
    "                               \"u\\U00002702-\\U000027B0\"\n",
    "                               \"u\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d1e30e4-6548-4a6b-bc0b-e7766f4cc01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie, it was '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie, it was 👍\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af778d9b-1a9d-4c1d-8d0c-20b6b79ae84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\rahul\\anaconda\\lib\\site-packages (2.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "463f4cda-c657-4de6-96b2-0eb7fae16657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is 🔥'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ce45c-bcb6-4924-b083-e82adf90181a",
   "metadata": {},
   "source": [
    "## TOKENIZATION\n",
    "#### 1. USING THE SPLIT FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b38b481e-8164-4edd-8b0c-ed4a00fbf2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WORD TOKENIZATION\n",
    "a = 'I am going to delhi'\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14b3d8d8-fc26-4936-ab57-76d99ab54b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iam going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "b = 'Iam going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "b.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a17d744-8e96-4661-95dc-2989bb49ccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem with split function\n",
    "c = 'I am going to delhi'\n",
    "c.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79a85959-6342-4143-ae96-d789143247fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 'Where do think I should go? I have 3 day holiday'\n",
    "d.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fcd89-fa57-4add-978d-2fa70db3eab0",
   "metadata": {},
   "source": [
    "## 2.REGULAR EXPRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff02411a-4ce1-44ee-9276-cddbdce11cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10164\\3355912277.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  tokens = re.findall(\"[\\w']+\", e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "e = 'I am going to delhi'\n",
    "tokens = re.findall(\"[\\w']+\", e)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38568749-ea07-4164-94d7-39b72b2ee155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05362085-34b9-4b22-a95c-bf1fe24a1956",
   "metadata": {},
   "source": [
    "## 3.NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "919c64a9-4f46-4738-a583-1787fb9cb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e2f1661-57aa-424c-91d3-d5c32950dc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'goind', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am goind to visit delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0347f280-53ec-4e60-9cfa-764d26c087b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a6491ec-9afb-4627-8d15-f3cc40a3293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04f51429-2fab-4ec0-9d5f-1077c1760032",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're  here to help! mail us at gks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "196698b1-51b9-46e4-bf12-0430b4c94e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dca658e3-a136-4bf9-985e-fc6025819d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'gks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fad07f5-70bb-491a-93c8-3920089ac258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99300f94-70ed-407b-b68d-ca844b5a99ca",
   "metadata": {},
   "source": [
    "## STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "459f2823-77e6-4c90-9fe5-647cde503628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8dfb867-d403-4301-bdb4-330ff5d5d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59559d7b-1e89-4671-ab0c-70070b904290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea488aa9-c69c-41ab-9265-72d2c4e46e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my all time favourite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen some 15 or more times in the last 25 years.\n"
     ]
    }
   ],
   "source": [
    "text = \"probably my all time favourite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen some 15 or more times in the last 25 years.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5523c466-d205-4aec-ab48-830f15342c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my all time favourit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen some 15 or more time in the last 25 years.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c34a6a-05af-4323-b695-7218293e5533",
   "metadata": {},
   "source": [
    " -Here after doing stemming the words like probably, movie, sacrifice etc are converted to probabl, movi, sacrific\n",
    "- To solve this issue we will do Lemmetization.\n",
    "- Work of both Stemming and Lemmetization are same.\n",
    "- The difference is, Lemmetization is slow compared to Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9157a-515d-489e-8301-3523f9d4df57",
   "metadata": {},
   "source": [
    "## LEMMATIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba09b998-4198-4bf5-83a5-0f02535df217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem  import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5129f53d-44aa-413f-aa09-78d5f6baf0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the WordNet corpus\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# You might also need to download the 'omw-1.4' package for wordnet\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "755a82e8-d810-4703-b495-5a9e0c7ea590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "aws                 aws                 \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He aws running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations = \"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "    \n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6a69b-9bb3-4b1a-8d7d-f5992fbe28d6",
   "metadata": {},
   "source": [
    "## CV_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "20b3742d-3504-471a-a096-8643c2380d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5dea7123-a561-4d10-97e8-d25c8e2ab238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5b0de0d-1706-41c3-a7f3-ae05458df7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words\"] = \"default value\"\n",
    "df[\"sentences\"] = \"default value\"\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df.at[i,\"words\"]=list(\"\")\n",
    "    df.at[i,\"sentences\"] = list(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d94bc4ee-fcfa-4736-9cc9-6387a3c814dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8fedcbc2-d746-455f-9ae2-8abcd54ad478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  review sentiment words sentences\n",
      "0               []    []        []\n",
      "1               []    []        []\n",
      "2               []    []        []\n",
      "3               []    []        []\n",
      "4               []    []        []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Assuming df is already defined and contains the necessary data\n",
    "\n",
    "# Function to ensure the text is a string\n",
    "def ensure_string(text):\n",
    "    if isinstance(text, list):\n",
    "        return \" \".join(text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'review' column\n",
    "df['review'] = df['review'].apply(ensure_string)\n",
    "\n",
    "# Tokenize sentences\n",
    "for i in range(499):\n",
    "    review_text = df.loc[i, \"review\"]\n",
    "    l1 = sent_tokenize(review_text)\n",
    "    df.at[i, \"sentiment\"] = l1\n",
    "\n",
    "# Print the resulting DataFrame to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61589413-1338-4dfa-9193-390cb6b80d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 3.4727609157562256 secs.\n"
     ]
    }
   ],
   "source": [
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3ac0e537-ed8e-483e-a415-a8be4d7fc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(df.shape[0]):\n",
    "    df.at[k,\"words\"]=list(\"\")\n",
    "    for j in range(len(df.loc[k,\"sentences\"])):\n",
    "        df.at[k,\"words\"].extend(lemmatize_sentence(df.loc[k,\"sentences\"][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2b5c03c9-fa32-4c60-a640-36cf65bc5dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c70ed814-0bd5-4d2c-9b5d-fdfbd7f1da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words_sentences\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a8d6bdd2-e7b2-47cb-82ce-ed2df5019495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  review sentiment words sentences words_sentences\n",
      "0               []    []        []                \n",
      "1               []    []        []                \n",
      "2               []    []        []                \n",
      "3               []    []        []                \n",
      "4               []    []        []                \n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary data\n",
    "\n",
    "# Function to concatenate words in a list\n",
    "def concatenate_words(words):\n",
    "    if not words:\n",
    "        return \"\"  # Return an empty string if the list is empty\n",
    "    return functools.reduce(lambda a, b: str(a) + \" \" + str(b), words, \"\")\n",
    "\n",
    "# Apply the function to each row\n",
    "for k in range(df.shape[0]):\n",
    "    words = df.loc[k, \"words\"]\n",
    "    df.loc[k, \"words_sentences\"] = concatenate_words(words)\n",
    "\n",
    "# Print the resulting DataFrame to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9386b801-930b-4dde-808e-5aa5772cbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d8ab178-2929-47de-a9af-f609be04b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    \n",
      "1    \n",
      "2    \n",
      "3    \n",
      "4    \n",
      "Name: words_sentences, dtype: object\n",
      "0\n",
      "50000\n",
      "Error: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains the necessary data\n",
    "\n",
    "# Print out the first few rows of the 'words_sentences' column to inspect\n",
    "print(df['words_sentences'].head())\n",
    "\n",
    "# Check for empty or null values\n",
    "print(df['words_sentences'].isnull().sum())  # Count of null values\n",
    "print(df['words_sentences'].apply(lambda x: len(str(x).strip()) == 0).sum())  # Count of empty strings\n",
    "\n",
    "# Fill null values with an empty string\n",
    "df['words_sentences'].fillna('', inplace=True)\n",
    "\n",
    "# Remove rows with empty strings in 'words_sentences'\n",
    "df = df[df['words_sentences'].apply(lambda x: len(str(x).strip()) > 0)]\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "\n",
    "# Fit and transform the text data\n",
    "try:\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['words_sentences'])\n",
    "    print(tfidf_matrix)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7e66dac6-dcba-4eef-a35e-59e10ede0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix is not defined.\n"
     ]
    }
   ],
   "source": [
    "# Check if tfidf_matrix is defined\n",
    "if 'tfidf_matrix' in locals():\n",
    "    dense = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "    print(dense.head())\n",
    "else:\n",
    "    print(\"tfidf_matrix is not defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d4fe6c54-fe0e-42db-a91f-08dc07cbe449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dense = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8fbf68e3-3fac-462d-9df8-497e4b32ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=df[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "89594ab1-a9d3-4789-be17-9ba7e81b7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "20bf8a74-ef5d-4f33-bf4f-ad323fcfdc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "819e2c65-74af-405e-b232-8a4d24fcb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_1=pd.DataFrame(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f4ad6cb9-9f66-47c3-9da6-2781b3fbd817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [review]\n",
      "Index: []\n",
      "The DataFrame or Series is empty.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df_y_1 is already defined\n",
    "\n",
    "# Inspect the DataFrame or Series\n",
    "print(df_y_1.head())\n",
    "\n",
    "# Check if it's empty\n",
    "if df_y_1.empty:\n",
    "    print(\"The DataFrame or Series is empty.\")\n",
    "else:\n",
    "    # Initialize the LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Apply LabelEncoder and handle the transformation\n",
    "    df_y_enc = df_y_1.apply(lambda x: le.fit_transform(x) if x.notnull().any() else x)\n",
    "    print(df_y_enc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6e1d0ce3-fac4-4c09-8bcd-f938dca3b732",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_y_enc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_y_enc\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_y_enc' is not defined"
     ]
    }
   ],
   "source": [
    "df_y_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8477e-7d08-48b1-a3a0-3c3bdeb6c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d1e0832d-125b-4db9-b7f5-b4926e48934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC=GradientBoostingClassifier(n_estimators=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7f9a6209-0f2b-4729-a5d1-2a4ab485d77a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gb_c\u001b[38;5;241m=\u001b[39mGBC\u001b[38;5;241m.\u001b[39mfit(dense,df_y_enc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dense' is not defined"
     ]
    }
   ],
   "source": [
    "gb_c=GBC.fit(dense,df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42187775-171f-41c9-a162-ac8b072b807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC.score(dense,df_y_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
